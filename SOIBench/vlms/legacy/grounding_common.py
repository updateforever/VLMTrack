# -*- coding: utf-8 -*-
"""
SOIBench/vlms/grounding_common.py
Grounding æ¨ç†é€šç”¨å‡½æ•°å’Œä¸»æµç¨‹
æ”¯æŒä»»æ„ VLM æ¨¡å‹é€šè¿‡é€‚é…å™¨æ¥å…¥
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Any
from tqdm import tqdm
from PIL import Image, ImageDraw, ImageFont, ImageColor


_ADDITIONAL_COLORS = [name for (name, _) in ImageColor.colormap.items()]


def plot_bounding_boxes(im: Image.Image, bboxes: List[List[float]], save_path: str):
    """
    åœ¨å›¾ä¸Šç”» bbox
    
    å‚æ•°:
        im: PIL Image å¯¹è±¡
        bboxes: List[List[float]]ï¼Œæ¯ä¸ªä¸º [x1,y1,x2,y2] åƒç´ åæ ‡
        save_path: ä¿å­˜è·¯å¾„
    """
    if not bboxes:
        return
    
    img = im.copy()
    draw = ImageDraw.Draw(img)
    colors = ["red", "green", "blue", "yellow", "orange", "pink", "purple"] + _ADDITIONAL_COLORS
    
    try:
        font = ImageFont.truetype("NotoSansCJK-Regular.ttc", size=14)
    except Exception:
        font = ImageFont.load_default()
    
    for i, bbox in enumerate(bboxes):
        color = colors[i % len(colors)]
        x1, y1, x2, y2 = [int(round(v)) for v in bbox]
        draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=3)
        draw.text((x1 + 4, y1 + 4), f"Pred-{i}", fill=color, font=font)
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    img.save(save_path)


def process_description_levels(output_en: Dict) -> List[str]:
    """
    å¤„ç†æè¿°æ–‡æœ¬çš„å››ä¸ªå±‚çº§ï¼Œæ·»åŠ åˆé€‚çš„æ ‡ç‚¹
    
    å‚æ•°:
        output_en: åŒ…å« level1-4 çš„å­—å…¸
    
    è¿”å›:
        å¤„ç†åçš„æè¿°æ–‡æœ¬åˆ—è¡¨
    """
    desc_parts = []
    for idx, k in enumerate(["level1", "level2", "level3", "level4"], 1):
        v = (output_en.get(k, "") or "").strip()
        if v:
            # ç§»é™¤æœ«å°¾çš„æ ‡ç‚¹ç¬¦å·
            v = v.rstrip('.,;:!?')
            
            # è½¬ä¸ºå°å†™
            v = v[0].lower() + v[1:] if len(v) > 0 else v
            
            # æ·»åŠ æ ‡ç‚¹
            if idx in [1, 2]:  # Level 1, 2: é€—å·
                v = v + ','
            else:  # Level 3, 4: å¥å·
                v = v + '.'
            
            desc_parts.append(v)
    
    return desc_parts


def load_and_fix_paths(jsonl_path: str, dataset_name: str, image_roots: Dict[str, str]) -> List[Dict]:
    """
    è¯»å–æè¿° jsonlï¼Œå¹¶æŠŠ image_path ä¿®å¤ä¸ºç»å¯¹è·¯å¾„
    æŠ½å– output-en çš„ level1 åˆ° level4 æ‹¼æˆæè¿°æ–‡æœ¬
    
    å‚æ•°:
        jsonl_path: jsonl æ–‡ä»¶è·¯å¾„
        dataset_name: æ•°æ®é›†åç§°
        image_roots: æ•°æ®é›†å›¾åƒæ ¹ç›®å½•å­—å…¸
    
    è¿”å›:
        æœ‰æ•ˆæ ·æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«:
            - original_item: åŸå§‹ JSONL è¡Œ
            - image_path: ä¿®å¤åçš„ç»å¯¹è·¯å¾„
            - desc_parts: å¤„ç†åçš„æè¿°æ–‡æœ¬åˆ—è¡¨
            - dataset_name: æ•°æ®é›†åç§°
            - frame_idx: å¸§ç´¢å¼•
    """
    image_root = image_roots.get(dataset_name)
    if not image_root:
        return []
    
    valid = []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)
            
            # æ³¨æ„ï¼šä¸è¦è·³è¿‡ skip å¸§ï¼
            # skip åªæ˜¯äººç±»æ ‡æ³¨æ—¶è·³è¿‡ï¼ŒVLM ç®—æ³•éœ€è¦å¯¹æ‰€æœ‰å¸§éƒ½è¿›è¡Œæ¨ç†
            
            # æå–æè¿°æ–‡æœ¬å¹¶æ·»åŠ åˆé€‚çš„æ ‡ç‚¹
            output_en = item.get("output-en", {}) or {}
            desc_parts = process_description_levels(output_en)
            
            if not desc_parts:
                # å¦‚æœæ²¡æœ‰æè¿°ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬
                print(f"  âš ï¸  WARNING: åºåˆ— {os.path.basename(jsonl_path)} çš„å¸§ {item.get('frame_idx')} ç¼ºå°‘æè¿°æ–‡æœ¬ï¼Œä½¿ç”¨é»˜è®¤ prompt")
                desc_parts = ["the target object."]
            
            # ä¿®å¤å›¾åƒè·¯å¾„
            rel = item.get("image_path", "")
            if not rel:
                continue
            if rel.startswith("/"):
                rel = rel[1:]
            
            # å°è¯•å¤šç§è·¯å¾„ç»„åˆæ–¹å¼
            possible_paths = [
                os.path.join(image_root, rel),
            ]
            
            # LaSOT ç‰¹æ®Šè·¯å¾„: éœ€è¦åœ¨ä¸­é—´æ’å…¥å¹´ä»½ç›®å½•
            if len(rel) > 10:
                possible_paths.append(os.path.join(image_root, rel[6:10], rel))
            
            # MGIT/TNL2K ç‰¹æ®Šè·¯å¾„
            if len(rel.split('/')) > 2:
                parts = rel.split('/')
                possible_paths.append(os.path.join(image_root, parts[1], 'imgs', parts[2][1:]))
                possible_paths.append(os.path.join(image_root, parts[1], 'imgs', parts[2]))
            
            abs_path = None
            for p in possible_paths:
                if p and os.path.exists(p):
                    abs_path = p
                    break
            
            if abs_path:
                valid.append({
                    "original_item": item,
                    "image_path": abs_path,
                    "desc_parts": desc_parts,
                    "dataset_name": dataset_name,
                    "frame_idx": item.get("frame_idx", "unknown"),
                })
    
    return valid


def _count_lines(path: str) -> int:
    """
    ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°ï¼Œç”¨äºæ–­ç‚¹ç»­è·‘
    """
    if not os.path.exists(path):
        return 0
    n = 0
    with open(path, "r", encoding="utf-8") as f:
        for _ in f:
            n += 1
    return n


def run_grounding_inference(
    adapter,
    engine,
    jsonl_dir: str,
    dataset_name: str,
    image_roots: Dict[str, str],
    output_dir: str,
    vis_dir: str = None,
    max_new_tokens: int = 512,
):
    """
    è¿è¡Œ Grounding æ¨ç†çš„ä¸»æµç¨‹
    
    å‚æ•°:
        adapter: æ¨¡å‹é€‚é…å™¨å®ä¾‹
        engine: æ¨ç†å¼•æ“å®ä¾‹
        jsonl_dir: JSONL æ–‡ä»¶ç›®å½•
        dataset_name: æ•°æ®é›†åç§°
        image_roots: å›¾åƒæ ¹ç›®å½•å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        vis_dir: å¯è§†åŒ–ç›®å½•ï¼ˆå¯é€‰ï¼‰
        max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
    """
    # è·å–æ‰€æœ‰ JSONL æ–‡ä»¶å¹¶æ’åº
    jsonl_files = sorted([f for f in os.listdir(jsonl_dir) if f.endswith('_descriptions.jsonl')])
    if not jsonl_files:
        print(f"âš ï¸  ç›®å½•ä¸ºç©ºæˆ–æ²¡æœ‰ _descriptions.jsonl æ–‡ä»¶: {jsonl_dir}")
        return
    
    print(f"\nğŸ“‚ å¤„ç†æ•°æ®é›†: {dataset_name} ({len(jsonl_files)} ä¸ªåºåˆ—)")
    
    for jsonl_file in tqdm(jsonl_files, desc=f"å¤„ç† {dataset_name}", dynamic_ncols=True):
        seq_name = Path(jsonl_file).stem.replace("_descriptions", "").replace("_done", "")
        save_path = os.path.join(output_dir, f"{seq_name}_pred.jsonl")
        
        # æ–­ç‚¹ç»­è·‘: æ£€æŸ¥å·²å¤„ç†çš„è¡Œæ•°
        processed = _count_lines(save_path)
        jsonl_path = os.path.join(jsonl_dir, jsonl_file)
        samples = load_and_fix_paths(jsonl_path, dataset_name, image_roots)
        
        if processed >= len(samples):
            continue
        
        # ä»æ–­ç‚¹å¤„ç»§ç»­
        for s in samples[processed:]:
            img_path = s["image_path"]
            desc_parts = s["desc_parts"]
            
            # ä½¿ç”¨é€‚é…å™¨æ„é€  prompt
            prompt = adapter.build_prompt(desc_parts)
            
            # è°ƒç”¨æ¨ç†å¼•æ“
            try:
                raw_out = engine.chat(img_path, prompt, max_new_tokens=max_new_tokens)
            except Exception as e:
                print(f"  âŒ æ¨ç†å¤±è´¥: {e}")
                raw_out = ""
            
            # å¤„ç†ç©ºè¾“å‡º
            if not raw_out:
                record = s["original_item"].copy()
                record["model_response"] = raw_out
                record["parsed_bboxes"] = []
                with open(save_path, "a", encoding="utf-8") as f_out:
                    f_out.write(json.dumps(record, ensure_ascii=False) + "\n")
                continue
            
            # ä½¿ç”¨é€‚é…å™¨è§£æ bbox
            with Image.open(img_path) as img:
                w, h = img.size
                parsed = adapter.parse_response(raw_out, w, h)
            
            # ä¿å­˜ç»“æœ
            record = s["original_item"].copy()
            record["model_response"] = raw_out
            record["parsed_bboxes"] = parsed
            
            with open(save_path, "a", encoding="utf-8") as f_out:
                f_out.write(json.dumps(record, ensure_ascii=False) + "\n")
            
            # å¯é€‰: ä¿å­˜å¯è§†åŒ–
            if vis_dir and parsed:
                vis_path = os.path.join(vis_dir, f"{seq_name}_{s['frame_idx']}.jpg")
                with Image.open(img_path) as img:
                    plot_bounding_boxes(img, parsed, vis_path)
