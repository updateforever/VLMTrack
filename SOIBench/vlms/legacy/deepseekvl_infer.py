# -*- coding: utf-8 -*-
"""
SOIBench/vlms/deepseekvl_infer.py
DeepSeek-VL2 æ¨ç†å¼•æ“
æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œ API ä¸¤ç§æ¨¡å¼
é»˜è®¤ä½¿ç”¨ç¡…åŸºæµåŠ¨ API
"""

import os
import re
import json
import torch
from PIL import Image


class DeepSeekVLLocalEngine:
    """
    DeepSeek-VL2 æœ¬åœ°æ¨ç†å¼•æ“
    ä½¿ç”¨ transformers åŠ è½½æ¨¡å‹
    """
    
    def __init__(
        self,
        model_path: str = "/home/member/data1/MODEL_WEIGHTS_PUBLIC/deepseek-vl2-small/",
        device_map: str = "auto",
    ):
        from transformers import AutoModelForCausalLM
        from deepseek_vl.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM
        from deepseek_vl.utils.io import load_pil_images
        
        print(f"ğŸš€ åŠ è½½ DeepSeek-VL2 æœ¬åœ°æ¨¡å‹: {model_path}")
        
        self.vl_chat_processor = DeepseekVLV2Processor.from_pretrained(model_path)
        self.tokenizer = self.vl_chat_processor.tokenizer
        
        self.vl_gpt = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        self.vl_gpt = self.vl_gpt.to(torch.bfloat16).cuda().eval()
        
        self.load_pil_images = load_pil_images
        
        print("âœ… DeepSeek-VL2 æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = 512) -> str:
        """
        å•å¼ å›¾æ¨ç†
        
        å‚æ•°:
            image_path: å›¾åƒè·¯å¾„
            prompt: æ–‡æœ¬æç¤ºï¼ˆç›®æ ‡æè¿°ï¼‰
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            
        è¿”å›:
            æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        """
        # æ„é€  grounding prompt (ä½¿ç”¨ <|ref|> æ ‡è®°)
        full_prompt = f"<image>\n<|ref|>{prompt}<|/ref|>."
        
        # æ„é€ å¯¹è¯
        conversation = [
            {
                "role": "<|User|>",
                "content": full_prompt,
                "images": [image_path],
            },
            {"role": "<|Assistant|>", "content": ""},
        ]
        
        # åŠ è½½å›¾åƒ
        pil_images = self.load_pil_images(conversation)
        
        # å‡†å¤‡è¾“å…¥
        prepare_inputs = self.vl_chat_processor(
            conversations=conversation,
            images=pil_images,
            force_batchify=True,
            system_prompt=""
        ).to(self.vl_gpt.device)
        
        # è·å–å›¾åƒåµŒå…¥
        inputs_embeds = self.vl_gpt.prepare_inputs_embeds(**prepare_inputs)
        
        # ç”Ÿæˆ
        outputs = self.vl_gpt.language_model.generate(
            inputs_embeds=inputs_embeds,
            attention_mask=prepare_inputs.attention_mask,
            pad_token_id=self.tokenizer.eos_token_id,
            bos_token_id=self.tokenizer.bos_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
            max_new_tokens=max_new_tokens,
            do_sample=False,
            use_cache=True
        )
        
        # è§£ç 
        answer = self.tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)
        
        return answer


class DeepSeekVLAPIEngine:
    """
    DeepSeek-VL2 API æ¨ç†å¼•æ“
    ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
    é»˜è®¤ä½¿ç”¨ç¡…åŸºæµåŠ¨ API
    """
    
    def __init__(
        self,
        api_key: str = None,
        api_base_url: str = "https://api.siliconflow.cn/v1",
        model_name: str = "deepseek-ai/deepseek-vl2",
        temperature: float = 0.1,
        max_tokens: int = 512,
        retries: int = 3,
    ):
        from openai import OpenAI
        
        # è·å– API Key
        if api_key is None:
            # ä¼˜å…ˆä½¿ç”¨ SILICONFLOW_API_KEYï¼Œå…¶æ¬¡æ˜¯ DEEPSEEK_API_KEY
            api_key = os.getenv("SILICONFLOW_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
            if not api_key:
                raise ValueError("è¯·è®¾ç½® SILICONFLOW_API_KEY æˆ– DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡ï¼Œæˆ–ä¼ å…¥ api_key å‚æ•°")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url=api_base_url
        )
        
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.retries = retries
        
        print(f"ğŸš€ åˆå§‹åŒ– DeepSeek-VL2 API å¼•æ“")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   Base URL: {api_base_url}")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = None) -> str:
        """
        å•å¼ å›¾æ¨ç†
        
        å‚æ•°:
            image_path: å›¾åƒè·¯å¾„
            prompt: æ–‡æœ¬æç¤ºï¼ˆç›®æ ‡æè¿°ï¼‰
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤å€¼ï¼‰
            
        è¿”å›:
            æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        """
        import base64
        import time
        
        # è¯»å–å¹¶ç¼–ç å›¾åƒ
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        # æ„é€  grounding prompt (ä½¿ç”¨ <|ref|> æ ‡è®°)
        full_prompt = f"<|ref|>{prompt}<|/ref|>."
        
        # æ„é€ æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}"
                        }
                    },
                    {
                        "type": "text",
                        "text": full_prompt
                    }
                ]
            }
        ]
        
        # é‡è¯•é€»è¾‘
        for attempt in range(self.retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=max_new_tokens or self.max_tokens,
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = 2 ** attempt
                    print(f"âš ï¸  API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.retries}): {e}")
                    print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise


def parse_deepseekvl_bbox(response: str, image_width: int, image_height: int):
    """
    è§£æ DeepSeek-VL2 çš„ bbox è¾“å‡º
    
    DeepSeek-VL2 è¾“å‡ºæ ¼å¼:
    - ä½¿ç”¨ <box> å’Œ </box> æ ‡è®°
    - åæ ‡æ ¼å¼: [[x1, y1, x2, y2]]
    - åæ ‡å€¼æ˜¯å½’ä¸€åŒ–åæ ‡ (0-1000)
    
    å‚æ•°:
        response: æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦
        
    è¿”å›:
        [[x1, y1, x2, y2], ...] åƒç´ åæ ‡åˆ—è¡¨
    """
    bboxes = []
    
    # æå– <box> å’Œ </box> ä¹‹é—´çš„å†…å®¹
    box_pattern = r'<box>(.*?)</box>'
    matches = re.findall(box_pattern, response, re.DOTALL)
    
    for match in matches:
        # æå–æ•°å­—åæ ‡
        # æ”¯æŒæ ¼å¼: [[x1, y1, x2, y2]] æˆ– [x1, y1, x2, y2]
        coord_pattern = r'\[+\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\]+'
        coords = re.findall(coord_pattern, match)
        
        for coord in coords:
            try:
                # å½’ä¸€åŒ–åæ ‡ (0-1000) -> åƒç´ åæ ‡
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                # è½¬æ¢ä¸ºåƒç´ åæ ‡
                x1 = (x1_norm / 1000.0) * image_width
                y1 = (y1_norm / 1000.0) * image_height
                x2 = (x2_norm / 1000.0) * image_width
                y2 = (y2_norm / 1000.0) * image_height
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, image_width))
                y1 = max(0, min(y1, image_height))
                x2 = max(0, min(x2, image_width))
                y2 = max(0, min(y2, image_height))
                
                bboxes.append([x1, y1, x2, y2])
                
            except (ValueError, IndexError) as e:
                print(f"âš ï¸  è§£æåæ ‡å¤±è´¥: {coord}, é”™è¯¯: {e}")
                continue
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° <box> æ ‡è®°ï¼Œå°è¯•ç›´æ¥æå–æ•°å­—
    if not bboxes:
        # å°è¯•æå–ä»»ä½•å½¢å¼çš„å››å…ƒç»„æ•°å­—
        fallback_pattern = r'\[+\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\]+'
        coords = re.findall(fallback_pattern, response)
        
        for coord in coords:
            try:
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å½’ä¸€åŒ–åæ ‡ (0-1000)
                if all(0 <= c <= 1000 for c in [x1_norm, y1_norm, x2_norm, y2_norm]):
                    x1 = (x1_norm / 1000.0) * image_width
                    y1 = (y1_norm / 1000.0) * image_height
                    x2 = (x2_norm / 1000.0) * image_width
                    y2 = (y2_norm / 1000.0) * image_height
                    
                    x1 = max(0, min(x1, image_width))
                    y1 = max(0, min(y1, image_height))
                    x2 = max(0, min(x2, image_width))
                    y2 = max(0, min(y2, image_height))
                    
                    bboxes.append([x1, y1, x2, y2])
                    
            except (ValueError, IndexError):
                continue
    
    return bboxes


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•ç¡…åŸºæµåŠ¨ API
    engine = DeepSeekVLAPIEngine()
    
    # æµ‹è¯•æ¨ç†
    image_path = "test.jpg"
    prompt = "a red car"
    
    response = engine.chat(image_path, prompt)
    print(f"æ¨¡å‹è¾“å‡º: {response}")
    
    # è§£æ bbox
    img = Image.open(image_path)
    bboxes = parse_deepseekvl_bbox(response, img.width, img.height)
    print(f"è§£æçš„ bbox: {bboxes}")
