# -*- coding: utf-8 -*-
"""
SOIBench/vlms/model_adapters/deepseekvl.py
DeepSeek-VL2 æ¨¡å‹å®Œæ•´å®ç°
åŒ…å«æ¨ç†å¼•æ“ã€bbox è§£æå’Œé€‚é…å™¨
"""

import os
import re
import time
import base64
from typing import List
from .base import ModelAdapter


# ============================================================================
# æ¨ç†å¼•æ“
# ============================================================================

class DeepSeekVLLocalEngine:
    """DeepSeek-VL2 æœ¬åœ°æ¨ç†å¼•æ“"""
    
    def __init__(
        self,
        model_path: str = "/home/member/data1/MODEL_WEIGHTS_PUBLIC/deepseek-vl2-small/",
        device_map: str = "auto",
    ):
        import torch
        from transformers import AutoModelForCausalLM
        from deepseek_vl.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM
        from deepseek_vl.utils.io import load_pil_images
        
        print(f"ğŸš€ åŠ è½½ DeepSeek-VL2 æœ¬åœ°æ¨¡å‹: {model_path}")
        
        self.vl_chat_processor = DeepseekVLV2Processor.from_pretrained(model_path)
        self.tokenizer = self.vl_chat_processor.tokenizer
        
        self.vl_gpt = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        self.vl_gpt = self.vl_gpt.to(torch.bfloat16).cuda().eval()
        
        self.load_pil_images = load_pil_images
        
        print("âœ… DeepSeek-VL2 æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = 512) -> str:
        """å•å¼ å›¾æ¨ç†"""
        # æ„é€ å¯¹è¯
        conversation = [
            {
                "role": "<|User|>",
                "content": f"<image>\n<|ref|>{prompt}<|/ref|>.",
                "images": [image_path],
            },
            {"role": "<|Assistant|>", "content": ""},
        ]
        
        # åŠ è½½å›¾åƒ
        pil_images = self.load_pil_images(conversation)
        
        # å‡†å¤‡è¾“å…¥
        prepare_inputs = self.vl_chat_processor(
            conversations=conversation,
            images=pil_images,
            force_batchify=True,
            system_prompt=""
        ).to(self.vl_gpt.device)
        
        # è·å–å›¾åƒåµŒå…¥
        inputs_embeds = self.vl_gpt.prepare_inputs_embeds(**prepare_inputs)
        
        # ç”Ÿæˆ
        outputs = self.vl_gpt.language_model.generate(
            inputs_embeds=inputs_embeds,
            attention_mask=prepare_inputs.attention_mask,
            pad_token_id=self.tokenizer.eos_token_id,
            bos_token_id=self.tokenizer.bos_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
            max_new_tokens=max_new_tokens,
            do_sample=False,
            use_cache=True
        )
        
        # è§£ç 
        answer = self.tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)
        
        return answer


class DeepSeekVLAPIEngine:
    """DeepSeek-VL2 API æ¨ç†å¼•æ“"""
    
    def __init__(
        self,
        api_key: str = None,
        api_base_url: str = "https://api.siliconflow.cn/v1",
        model_name: str = "deepseek-ai/deepseek-vl2",
        temperature: float = 0.1,
        max_tokens: int = 512,
        retries: int = 3,
    ):
        from openai import OpenAI
        
        if api_key is None:
            api_key = os.getenv("SILICONFLOW_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
            if not api_key:
                raise ValueError("è¯·è®¾ç½® SILICONFLOW_API_KEY æˆ– DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        
        self.client = OpenAI(api_key=api_key, base_url=api_base_url)
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.retries = retries
        
        print(f"ğŸš€ åˆå§‹åŒ– DeepSeek-VL2 API å¼•æ“")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   Base URL: {api_base_url}")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = None) -> str:
        """å•å¼ å›¾æ¨ç†"""
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}},
                    {"type": "text", "text": f"<|ref|>{prompt}<|/ref|>."}
                ]
            }
        ]
        
        for attempt in range(self.retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=max_new_tokens or self.max_tokens,
                )
                return response.choices[0].message.content
            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = 2 ** attempt
                    print(f"âš ï¸  API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.retries}): {e}")
                    print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
                    raise


# ============================================================================
# Bbox è§£æ
# ============================================================================

def parse_deepseekvl_bbox(response: str, image_width: int, image_height: int) -> List[List[float]]:
    """
    è§£æ DeepSeek-VL2 çš„ bbox è¾“å‡º
    
    è¾“å‡ºæ ¼å¼:
    - ä½¿ç”¨ <box> å’Œ </box> æ ‡è®°
    - åæ ‡æ ¼å¼: [[x1, y1, x2, y2]]
    - åæ ‡å€¼æ˜¯å½’ä¸€åŒ–åæ ‡ (0-1000)
    """
    bboxes = []
    
    # æå– <box> å’Œ </box> ä¹‹é—´çš„å†…å®¹
    box_pattern = r'<box>(.*?)</box>'
    matches = re.findall(box_pattern, response, re.DOTALL)
    
    for match in matches:
        coord_pattern = r'\[+\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\]+'
        coords = re.findall(coord_pattern, match)
        
        for coord in coords:
            try:
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                x1 = (x1_norm / 1000.0) * image_width
                y1 = (y1_norm / 1000.0) * image_height
                x2 = (x2_norm / 1000.0) * image_width
                y2 = (y2_norm / 1000.0) * image_height
                
                x1 = max(0, min(x1, image_width))
                y1 = max(0, min(y1, image_height))
                x2 = max(0, min(x2, image_width))
                y2 = max(0, min(y2, image_height))
                
                bboxes.append([x1, y1, x2, y2])
            except (ValueError, IndexError) as e:
                print(f"âš ï¸  è§£æåæ ‡å¤±è´¥: {coord}, é”™è¯¯: {e}")
                continue
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° <box> æ ‡è®°ï¼Œå°è¯•ç›´æ¥æå–æ•°å­—
    if not bboxes:
        fallback_pattern = r'\[+\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\]+'
        coords = re.findall(fallback_pattern, response)
        
        for coord in coords:
            try:
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                if all(0 <= c <= 1000 for c in [x1_norm, y1_norm, x2_norm, y2_norm]):
                    x1 = (x1_norm / 1000.0) * image_width
                    y1 = (y1_norm / 1000.0) * image_height
                    x2 = (x2_norm / 1000.0) * image_width
                    y2 = (y2_norm / 1000.0) * image_height
                    
                    x1 = max(0, min(x1, image_width))
                    y1 = max(0, min(y1, image_height))
                    x2 = max(0, min(x2, image_width))
                    y2 = max(0, min(y2, image_height))
                    
                    bboxes.append([x1, y1, x2, y2])
            except (ValueError, IndexError):
                continue
    
    return bboxes


# ============================================================================
# é€‚é…å™¨
# ============================================================================

class DeepSeekVLAdapter(ModelAdapter):
    """DeepSeek-VL2 æ¨¡å‹é€‚é…å™¨"""
    
    def build_prompt(self, desc_parts: List[str]) -> str:
        """æ„é€  DeepSeek-VL2 çš„ prompt"""
        description = " ".join(desc_parts).strip()
        return f"<|ref|>{description}<|/ref|>."
    
    def parse_response(self, response: str, img_width: int, img_height: int) -> List[List[float]]:
        """è§£æ DeepSeek-VL2 çš„è¾“å‡º"""
        return parse_deepseekvl_bbox(response, img_width, img_height)
    
    def create_engine(self, args):
        """åˆ›å»º DeepSeek-VL2 æ¨ç†å¼•æ“"""
        if args.mode == 'local':
            return DeepSeekVLLocalEngine(args.model_path)
        else:
            return DeepSeekVLAPIEngine(
                api_key=args.api_key,
                api_base_url=args.api_base_url,
                model_name=args.api_model_name,
                temperature=args.api_temperature,
                max_tokens=args.api_max_tokens,
                retries=args.api_retries,
            )
    
    def get_default_model_path(self) -> str:
        return "/home/member/data1/MODEL_WEIGHTS_PUBLIC/deepseek-vl2-small/"
    
    def get_default_api_model_name(self) -> str:
        return "deepseek-ai/deepseek-vl2"
    
    def get_default_api_base_url(self) -> str:
        return "https://api.siliconflow.cn/v1"
