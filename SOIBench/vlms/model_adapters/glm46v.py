# -*- coding: utf-8 -*-
"""
SOIBench/vlms/model_adapters/glm46v.py
GLM-4.6V æ¨¡å‹å®Œæ•´å®ç°
åŒ…å«æ¨ç†å¼•æ“ã€bbox è§£æå’Œé€‚é…å™¨
"""

import os
import re
from typing import List
from .base import ModelAdapter


# ============================================================================
# æ¨ç†å¼•æ“
# ============================================================================

class GLM46VLocalEngine:
    """GLM-4.6V æœ¬åœ°æ¨ç†å¼•æ“"""
    
    def __init__(self, model_path: str, device_map: str = "auto"):
        from transformers import AutoModelForCausalLM, AutoTokenizer
        import torch
        
        print(f"ğŸš€ åŠ è½½ GLM-4.6V æœ¬åœ°æ¨¡å‹: {model_path}")
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype="auto",
            device_map=device_map,
            trust_remote_code=True
        ).eval()
        
        print("âœ… GLM-4.6V æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = 512) -> str:
        """å•å¼ å›¾æ¨ç†"""
        import torch
        from PIL import Image
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # æ„é€ è¾“å…¥
        inputs = self.tokenizer.apply_chat_template(
            [{"role": "user", "image": image, "content": prompt}],
            add_generation_prompt=True,
            tokenize=True,
            return_tensors="pt",
            return_dict=True
        )
        
        inputs = inputs.to(self.model.device)
        
        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=False,
                temperature=0.1,
            )
        
        # è§£ç 
        response = self.tokenizer.decode(
            outputs[0][inputs['input_ids'].shape[1]:],
            skip_special_tokens=False
        )
        
        return response


class GLM46VAPIEngine:
    """GLM-4.6V API æ¨ç†å¼•æ“"""
    
    def __init__(
        self,
        api_key: str = None,
        api_base_url: str = "https://api.siliconflow.cn/v1",
        model_name: str = "zai-org/GLM-4.6V",
        temperature: float = 0.1,
        max_tokens: int = 512,
        retries: int = 3,
    ):
        from openai import OpenAI
        
        if api_key is None:
            api_key = os.getenv("SILICONFLOW_API_KEY") or os.getenv("ZHIPUAI_API_KEY")
            if not api_key:
                raise ValueError("è¯·è®¾ç½® SILICONFLOW_API_KEY æˆ– ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")
        
        self.client = OpenAI(api_key=api_key, base_url=api_base_url)
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.retries = retries
        
        print(f"ğŸš€ åˆå§‹åŒ– GLM-4.6V API å¼•æ“")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   Base URL: {api_base_url}")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = None) -> str:
        """å•å¼ å›¾æ¨ç†"""
        import base64
        import time
        
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}},
                    {"type": "text", "text": prompt}
                ]
            }
        ]
        
        for attempt in range(self.retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=max_new_tokens or self.max_tokens,
                )
                return response.choices[0].message.content
            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = 2 ** attempt
                    print(f"âš ï¸  API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.retries}): {e}")
                    print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥: {e}")
                    raise


# ============================================================================
# Bbox è§£æ
# ============================================================================

def parse_glm46v_bbox(response: str, image_width: int, image_height: int) -> List[List[float]]:
    """
    è§£æ GLM-4.6V çš„ bbox è¾“å‡º
    
    è¾“å‡ºæ ¼å¼:
    - ä½¿ç”¨ <|begin_of_box|> å’Œ <|end_of_box|> æ ‡è®°
    - åæ ‡æ ¼å¼: [x1, y1, x2, y2]
    - åæ ‡å€¼æ˜¯å½’ä¸€åŒ–åä¹˜ä»¥ 1000 çš„æ•´æ•°
    """
    bboxes = []
    
    # æå– <|begin_of_box|> å’Œ <|end_of_box|> ä¹‹é—´çš„å†…å®¹
    box_pattern = r'<\|begin_of_box\|>(.*?)<\|end_of_box\|>'
    matches = re.findall(box_pattern, response, re.DOTALL)
    
    for match in matches:
        coord_pattern = r'[\[\(<]?\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*[\]\)>]?'
        coords = re.findall(coord_pattern, match)
        
        for coord in coords:
            try:
                # å½’ä¸€åŒ–åæ ‡ (0-1000) -> åƒç´ åæ ‡
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                x1 = (x1_norm / 1000.0) * image_width
                y1 = (y1_norm / 1000.0) * image_height
                x2 = (x2_norm / 1000.0) * image_width
                y2 = (y2_norm / 1000.0) * image_height
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, image_width))
                y1 = max(0, min(y1, image_height))
                x2 = max(0, min(x2, image_width))
                y2 = max(0, min(y2, image_height))
                
                bboxes.append([x1, y1, x2, y2])
            except (ValueError, IndexError) as e:
                print(f"âš ï¸  è§£æåæ ‡å¤±è´¥: {coord}, é”™è¯¯: {e}")
                continue
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹æ®Šæ ‡è®°ï¼Œå°è¯•ç›´æ¥æå–æ•°å­—
    if not bboxes:
        fallback_pattern = r'\[?\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\]?'
        coords = re.findall(fallback_pattern, response)
        
        for coord in coords:
            try:
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                if all(0 <= c <= 1000 for c in [x1_norm, y1_norm, x2_norm, y2_norm]):
                    x1 = (x1_norm / 1000.0) * image_width
                    y1 = (y1_norm / 1000.0) * image_height
                    x2 = (x2_norm / 1000.0) * image_width
                    y2 = (y2_norm / 1000.0) * image_height
                    
                    x1 = max(0, min(x1, image_width))
                    y1 = max(0, min(y1, image_height))
                    x2 = max(0, min(x2, image_width))
                    y2 = max(0, min(y2, image_height))
                    
                    bboxes.append([x1, y1, x2, y2])
            except (ValueError, IndexError):
                continue
    
    return bboxes


# ============================================================================
# é€‚é…å™¨
# ============================================================================

class GLM46VAdapter(ModelAdapter):
    """GLM-4.6V æ¨¡å‹é€‚é…å™¨"""
    
    def build_prompt(self, desc_parts: List[str]) -> str:
        """æ„é€  GLM-4.6V çš„ prompt"""
        description = " ".join(desc_parts).strip()
        return f"Please pinpoint the bounding box in the image as per the given description: {description}"
    
    def parse_response(self, response: str, img_width: int, img_height: int) -> List[List[float]]:
        """è§£æ GLM-4.6V çš„è¾“å‡º"""
        return parse_glm46v_bbox(response, img_width, img_height)
    
    def create_engine(self, args):
        """åˆ›å»º GLM-4.6V æ¨ç†å¼•æ“"""
        if args.mode == 'local':
            return GLM46VLocalEngine(args.model_path)
        else:
            return GLM46VAPIEngine(
                api_key=args.api_key,
                api_base_url=args.api_base_url,
                model_name=args.api_model_name,
                temperature=args.api_temperature,
                max_tokens=args.api_max_tokens,
                retries=args.api_retries,
            )
    
    def get_default_model_path(self) -> str:
        return "/home/member/data1/MODEL_WEIGHTS_PUBLIC/GLM-4.6V-Flash/"
    
    def get_default_api_model_name(self) -> str:
        return "zai-org/GLM-4.6V"
    
    def get_default_api_base_url(self) -> str:
        return "https://api.siliconflow.cn/v1"
