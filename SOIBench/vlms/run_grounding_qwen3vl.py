# -*- coding: utf-8 -*-
"""
SOIBench/vlms/run_grounding_qwen3vl.py
Grounding ä¸»æµç¨‹è„šæœ¬
åŠŸèƒ½ï¼š
1ï¼‰è¯»å–æè¿° jsonlï¼Œä¿®å¤å›¾åƒè·¯å¾„
2ï¼‰è°ƒç”¨ qwen3vl_infer.py ä¸­çš„æœ¬åœ°æˆ– API å¼•æ“æ¨ç†
3ï¼‰è§£æè¾“å‡º bboxï¼Œå¹¶ç»Ÿä¸€ä¸ºåƒç´ åæ ‡
4ï¼‰ä¿å­˜ pred.jsonlï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘
5ï¼‰å¯é€‰ä¿å­˜å¯è§†åŒ–ç»“æœ
"""

import argparse
import glob
import json
import os
import re
from pathlib import Path

from tqdm import tqdm
from PIL import Image, ImageDraw, ImageFont, ImageColor

from qwen3vl_infer import Qwen3VLLocalEngine, qwen3vl_api_chat


_ADDITIONAL_COLORS = [name for (name, _) in ImageColor.colormap.items()]


def plot_bounding_boxes(im: Image.Image, bboxes, save_path: str):
    """
    åœ¨å›¾ä¸Šç”» bbox
    å‚æ•°:
        im: PIL Image å¯¹è±¡
        bboxes: List[List[float]]ï¼Œæ¯ä¸ªä¸º [x1,y1,x2,y2] åƒç´ åæ ‡
        save_path: ä¿å­˜è·¯å¾„
    """
    if not bboxes:
        return

    img = im.copy()
    draw = ImageDraw.Draw(img)
    colors = ["red", "green", "blue", "yellow", "orange", "pink", "purple"] + _ADDITIONAL_COLORS

    try:
        font = ImageFont.truetype("NotoSansCJK-Regular.ttc", size=14)
    except Exception:
        font = ImageFont.load_default()

    for i, bbox in enumerate(bboxes):
        color = colors[i % len(colors)]
        x1, y1, x2, y2 = [int(round(v)) for v in bbox]
        draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=3)
        draw.text((x1 + 4, y1 + 4), f"Pred-{i}", fill=color, font=font)

    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    img.save(save_path)


def _strip_code_fence(text: str) -> str:
    """
    å»æ‰ ```json / ``` ç­‰ä»£ç å—åŒ…è£¹
    """
    if not text:
        return ""
    t = text.strip()
    t = re.sub(r"^```[a-zA-Z0-9]*\s*", "", t)
    t = re.sub(r"\s*```$", "", t)
    return t.strip()


def _safe_float_list(x):
    """
    å°è¯•æŠŠè¾“å…¥è½¬æ¢æˆé•¿åº¦ä¸º 4 çš„ float list
    """
    if isinstance(x, (list, tuple)) and len(x) == 4:
        try:
            return [float(v) for v in x]
        except Exception:
            return None
    return None


def _clamp(v, lo, hi):
    """å°†å€¼é™åˆ¶åœ¨ [lo, hi] èŒƒå›´å†…"""
    return max(lo, min(hi, v))


def _fix_and_clip_bbox(b, w, h):
    """
    ä¿®æ­£ bbox åæ ‡é¡ºåºå¹¶è£å‰ªåˆ°å›¾åƒèŒƒå›´å†…
    å‚æ•°:
        b: [x1, y1, x2, y2]
        w: å›¾åƒå®½åº¦
        h: å›¾åƒé«˜åº¦
    è¿”å›:
        ä¿®æ­£åçš„ bbox
    """
    x1, y1, x2, y2 = b
    # ç¡®ä¿ x1 < x2, y1 < y2
    if x2 < x1:
        x1, x2 = x2, x1
    if y2 < y1:
        y1, y2 = y2, y1

    # è£å‰ªåˆ°å›¾åƒèŒƒå›´
    x1 = _clamp(x1, 0.0, float(w - 1))
    y1 = _clamp(y1, 0.0, float(h - 1))
    x2 = _clamp(x2, 0.0, float(w - 1))
    y2 = _clamp(y2, 0.0, float(h - 1))

    # ç¡®ä¿ bbox è‡³å°‘æœ‰ 1 åƒç´ å®½é«˜
    if abs(x2 - x1) < 1.0:
        x2 = _clamp(x1 + 1.0, 0.0, float(w - 1))
    if abs(y2 - y1) < 1.0:
        y2 = _clamp(y1 + 1.0, 0.0, float(h - 1))

    return [x1, y1, x2, y2]


def _convert_to_pixel_bbox(b, w, h):
    """
    æ”¯æŒä¸‰ç±»åæ ‡ä½“ç³»å¹¶ç»Ÿä¸€æˆåƒç´ åæ ‡
    1ï¼‰0 åˆ° 1 å½’ä¸€åŒ–åæ ‡
    2ï¼‰0 åˆ° 1000 å½’ä¸€åŒ–åæ ‡
    3ï¼‰åƒç´ åæ ‡
    å‚æ•°:
        b: [x1, y1, x2, y2]
        w: å›¾åƒå®½åº¦
        h: å›¾åƒé«˜åº¦
    è¿”å›:
        åƒç´ åæ ‡ [x1, y1, x2, y2]
    """
    x1, y1, x2, y2 = b
    maxv = max(x1, y1, x2, y2)
    minv = min(x1, y1, x2, y2)

    # åˆ¤æ–­æ˜¯ 0-1 å½’ä¸€åŒ–
    if 0.0 <= minv and maxv <= 1.0:
        return [x1 * w, y1 * h, x2 * w, y2 * h]

    # åˆ¤æ–­æ˜¯ 0-1000 å½’ä¸€åŒ–
    if 0.0 <= minv and maxv <= 1000.0:
        return [(x1 / 1000.0) * w, (y1 / 1000.0) * h, (x2 / 1000.0) * w, (y2 / 1000.0) * h]

    # å¦åˆ™è®¤ä¸ºæ˜¯åƒç´ åæ ‡
    return [x1, y1, x2, y2]


def extract_bboxes_from_model_output(text: str, img_width: int, img_height: int):
    """
    ä»æ¨¡å‹è¾“å‡ºä¸­è§£æ bbox
    æ”¯æŒå¤šç§æ ¼å¼:
    1ï¼‰JSON: {"bbox_2d":[...]} æˆ– [{"bbox_2d":[...]}]
    2ï¼‰JSON: [x1,y1,x2,y2]
    3ï¼‰æ–‡æœ¬ä¸­åŒ…å«å¤šä¸ª [x1,y1,x2,y2]
    4ï¼‰å…¼å®¹ 0 åˆ° 1ï¼Œ0 åˆ° 1000ï¼Œåƒç´ åæ ‡
    
    å‚æ•°:
        text: æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        img_width: å›¾åƒå®½åº¦
        img_height: å›¾åƒé«˜åº¦
    è¿”å›:
        List[[x1,y1,x2,y2]]ï¼Œåƒç´ åæ ‡
    """
    raw = text or ""
    t = _strip_code_fence(raw)
    if not t:
        return []

    bboxes = []

    # å°è¯•è§£æ JSON
    try:
        data = json.loads(t)

        if isinstance(data, dict):
            # å•ä¸ª bbox: {"bbox_2d": [x1,y1,x2,y2]}
            if "bbox_2d" in data:
                b = _safe_float_list(data["bbox_2d"])
                if b:
                    b = _convert_to_pixel_bbox(b, img_width, img_height)
                    bboxes.append(_fix_and_clip_bbox(b, img_width, img_height))

            # å¤šä¸ª bbox: {"bboxes": [{...}, {...}]}
            if "bboxes" in data and isinstance(data["bboxes"], list):
                for it in data["bboxes"]:
                    if isinstance(it, dict) and "bbox_2d" in it:
                        b = _safe_float_list(it["bbox_2d"])
                    else:
                        b = _safe_float_list(it)
                    if b:
                        b = _convert_to_pixel_bbox(b, img_width, img_height)
                        bboxes.append(_fix_and_clip_bbox(b, img_width, img_height))

        elif isinstance(data, list):
            # ç›´æ¥æ˜¯ä¸€ä¸ª bbox: [x1,y1,x2,y2]
            if len(data) == 4 and all(isinstance(x, (int, float)) for x in data):
                b = [float(x) for x in data]
                b = _convert_to_pixel_bbox(b, img_width, img_height)
                bboxes.append(_fix_and_clip_bbox(b, img_width, img_height))
            else:
                # å¤šä¸ª bbox: [[x1,y1,x2,y2], ...] æˆ– [{"bbox_2d": ...}, ...]
                for it in data:
                    if isinstance(it, dict) and "bbox_2d" in it:
                        b = _safe_float_list(it["bbox_2d"])
                    else:
                        b = _safe_float_list(it)
                    if b:
                        b = _convert_to_pixel_bbox(b, img_width, img_height)
                        bboxes.append(_fix_and_clip_bbox(b, img_width, img_height))

        if bboxes:
            return bboxes

    except Exception:
        pass

    # JSON è§£æå¤±è´¥ï¼Œå°è¯•æ­£åˆ™åŒ¹é… [x1,y1,x2,y2]
    matches = re.findall(r"\[([^\[\]]+)\]", t)
    for m in matches:
        nums = re.findall(r"[-+]?\d*\.?\d+(?:[eE][-+]?\d+)?", m)
        if len(nums) == 4:
            try:
                b = [float(x) for x in nums]
                b = _convert_to_pixel_bbox(b, img_width, img_height)
                bboxes.append(_fix_and_clip_bbox(b, img_width, img_height))
            except Exception:
                continue

    return bboxes


def load_and_fix_paths(jsonl_path: str, dataset_name: str, image_roots: dict):
    """
    è¯»å–æè¿° jsonlï¼Œå¹¶æŠŠ image_path ä¿®å¤ä¸ºç»å¯¹è·¯å¾„
    æŠ½å– output-en çš„ level1 åˆ° level4 æ‹¼æˆæè¿°æ–‡æœ¬
    
    å‚æ•°:
        jsonl_path: jsonl æ–‡ä»¶è·¯å¾„
        dataset_name: æ•°æ®é›†åç§°
        image_roots: æ•°æ®é›†å›¾åƒæ ¹ç›®å½•å­—å…¸
    è¿”å›:
        æœ‰æ•ˆæ ·æœ¬åˆ—è¡¨
    """
    image_root = image_roots.get(dataset_name)
    if not image_root:
        return []

    valid = []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            item = json.loads(line)

            # æ³¨æ„ï¼šä¸è¦è·³è¿‡ skip å¸§ï¼
            # skip åªæ˜¯äººç±»æ ‡æ³¨æ—¶è·³è¿‡ï¼ŒVLM ç®—æ³•éœ€è¦å¯¹æ‰€æœ‰å¸§éƒ½è¿›è¡Œæ¨ç†
            
            # æå–æè¿°æ–‡æœ¬
            output_en = item.get("output-en", {}) or {}
            desc_parts = []
            for k in ["level1", "level2", "level3", "level4"]:
                v = (output_en.get(k, "") or "").strip()
                if v:
                    desc_parts.append(v)

            full_desc = " ".join(desc_parts).strip()
            if not full_desc:
                # å¦‚æœæ²¡æœ‰æè¿°ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬
                print(f"  âš ï¸  WARNING: åºåˆ— {os.path.basename(jsonl_path)} çš„å¸§ {item.get('frame_idx')} ç¼ºå°‘æè¿°æ–‡æœ¬ï¼Œä½¿ç”¨é»˜è®¤ prompt")
                full_desc = "the target object"

            # ä¿®å¤å›¾åƒè·¯å¾„
            rel = item.get("image_path", "")
            if not rel:
                continue
            if rel.startswith("/"):
                rel = rel[1:]
            
            # å°è¯•å¤šç§è·¯å¾„ç»„åˆæ–¹å¼
            possible_paths = [
                os.path.join(image_root, rel),
            ]
            
            # LaSOT ç‰¹æ®Šè·¯å¾„: éœ€è¦åœ¨ä¸­é—´æ’å…¥å¹´ä»½ç›®å½•
            if len(rel) > 10:
                possible_paths.append(os.path.join(image_root, rel[6:10], rel))
            
            # MGIT/TNL2K ç‰¹æ®Šè·¯å¾„
            if len(rel.split('/')) > 2:
                parts = rel.split('/')
                possible_paths.append(os.path.join(image_root, parts[1], 'imgs', parts[2][1:]))
                possible_paths.append(os.path.join(image_root, parts[1], 'imgs', parts[2]))

            abs_path = None
            for p in possible_paths:
                if p and os.path.exists(p):
                    abs_path = p
                    break
            
            if abs_path:
                valid.append({
                    "original_item": item,
                    "image_path": abs_path,
                    "text_prompt": full_desc,
                    "dataset_name": dataset_name,
                    "frame_idx": item.get("frame_idx", "unknown"),
                })

    return valid


def build_prompt(description: str) -> str:
    """
    æ„å»º Grounding prompt
    """
    return (
        "You are a visual grounding model. Given an image and a target description, output the target bounding box.\n"
        f"Target description: {description}\n"
        "Locate the description target, output its bbox coordinates using JSON format."
    )


def _count_lines(path: str) -> int:
    """
    ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°ï¼Œç”¨äºæ–­ç‚¹ç»­è·‘
    """
    if not os.path.exists(path):
        return 0
    n = 0
    with open(path, "r", encoding="utf-8") as f:
        for _ in f:
            n += 1
    return n


def main():
    parser = argparse.ArgumentParser(description="SOIBench Grounding è¯„æµ‹è„šæœ¬")

    # æ¨ç†æ¨¡å¼
    parser.add_argument("--mode", type=str, default="local", choices=["local", "api"],
                        help="æ¨ç†æ¨¡å¼: local(æœ¬åœ°) æˆ– api(APIè°ƒç”¨)")
    parser.add_argument("--model_path", type=str, default="",
                        help="æœ¬åœ°æ¨¡å‹è·¯å¾„ (mode=local æ—¶å¿…éœ€)")
    parser.add_argument("--max_new_tokens", type=int, default=256,
                        help="æœ€å¤§ç”Ÿæˆ token æ•°")

    # API é…ç½®
    parser.add_argument("--api_model_name", type=str, default="qwen-vl-max",
                        help="API æ¨¡å‹åç§°")
    parser.add_argument("--api_base_url", type=str, 
                        default="https://dashscope.aliyuncs.com/compatible-mode/v1",
                        help="API base URL")
    parser.add_argument("--api_key_env", type=str, default="sk-61547e720ce8407aa44f4511051903b0",
                        help="API key")
    parser.add_argument("--api_temperature", type=float, default=0.1,
                        help="API æ¸©åº¦å‚æ•°")
    parser.add_argument("--api_max_tokens", type=int, default=256,
                        help="API æœ€å¤§ token æ•°")
    parser.add_argument("--api_retries", type=int, default=3,
                        help="API é‡è¯•æ¬¡æ•°")

    # å®éªŒé…ç½®
    parser.add_argument("--exp_tag", type=str, default="run",
                        help="å®éªŒæ ‡ç­¾")
    parser.add_argument("--save_debug_vis", action="store_true",
                        help="æ˜¯å¦ä¿å­˜è°ƒè¯•å¯è§†åŒ–")

    # æ•°æ®é›†å›¾åƒæ ¹ç›®å½•
    parser.add_argument("--lasot_root", type=str, 
                        default="/home/member/data1/DATASETS_PUBLIC/LaSOT/LaSOTBenchmark",
                        help="LaSOT æ•°æ®é›†å›¾åƒæ ¹ç›®å½•")
    parser.add_argument("--mgit_root", type=str, 
                        default="/home/member/data1/DATASETS_PUBLIC/MGIT/VideoCube/MGIT-Test/data/test",
                        help="MGIT æ•°æ®é›†å›¾åƒæ ¹ç›®å½•")
    parser.add_argument("--tnl2k_root", type=str, 
                        default="/home/member/data1/DATASETS_PUBLIC/TNL2K/TNL2K_CVPR2021/test",
                        help="TNL2K æ•°æ®é›†å›¾åƒæ ¹ç›®å½•")

    # JSONL æè¿°æ–‡ä»¶ç›®å½•
    parser.add_argument("--lasot_jsonl", type=str, 
                        default="/home/member/data2/wyp/SUTrack/SOIBench/data/test/lasot",
                        help="LaSOT JSONL æè¿°æ–‡ä»¶ç›®å½•")
    parser.add_argument("--mgit_jsonl", type=str, 
                        default="/home/member/data2/wyp/SUTrack/SOIBench/data/test/mgit",
                        help="MGIT JSONL æè¿°æ–‡ä»¶ç›®å½•")
    parser.add_argument("--tnl2k_jsonl", type=str, 
                        default="/home/member/data2/wyp/SUTrack/SOIBench/data/test/tnl2k",
                        help="TNL2K JSONL æè¿°æ–‡ä»¶ç›®å½•")

    # è¾“å‡ºç›®å½•
    parser.add_argument("--output_root", type=str, default="./results",
                        help="ç»“æœä¿å­˜æ ¹ç›®å½•")

    args = parser.parse_args()

    # æ„å»ºå›¾åƒæ ¹ç›®å½•å­—å…¸
    image_roots = {
        "lasot": args.lasot_root,
        "mgit": args.mgit_root,
        "tnl2k": args.tnl2k_root
    }

    # åˆå§‹åŒ–æ¨ç†å¼•æ“
    engine = None
    if args.mode == "local":
        if not args.model_path:
            raise ValueError("mode=local æ—¶å¿…é¡»æä¾› --model_path")
        print(f"ğŸš€ åŠ è½½æœ¬åœ°æ¨¡å‹: {args.model_path}")
        engine = Qwen3VLLocalEngine(args.model_path)

    # æ„å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    if args.lasot_jsonl and os.path.exists(args.lasot_jsonl):
        tasks.append(("lasot", args.lasot_jsonl))
    if args.mgit_jsonl and os.path.exists(args.mgit_jsonl):
        tasks.append(("mgit", args.mgit_jsonl))
    if args.tnl2k_jsonl and os.path.exists(args.tnl2k_jsonl):
        tasks.append(("tnl2k", args.tnl2k_jsonl))

    if not tasks:
        print("âŒ æœªæŒ‡å®šä»»ä½•æœ‰æ•ˆçš„æ•°æ®ç›®å½•")
        return

    # å¤„ç†æ¯ä¸ªæ•°æ®é›†
    for dataset_name, jsonl_dir in tasks:
        out_dir = os.path.join(args.output_root, dataset_name, f"{args.mode}_{args.exp_tag}")
        os.makedirs(out_dir, exist_ok=True)

        vis_dir = None
        if args.save_debug_vis:
            vis_dir = os.path.join(out_dir, "vis_debug")
            os.makedirs(vis_dir, exist_ok=True)

        jsonl_files = sorted(glob.glob(os.path.join(jsonl_dir, "*.jsonl")))
        if not jsonl_files:
            print(f"âš ï¸  ç›®å½•ä¸ºç©º: {jsonl_dir}")
            continue

        print(f"\nğŸ“‚ å¤„ç†æ•°æ®é›†: {dataset_name} ({len(jsonl_files)} ä¸ªåºåˆ—)")

        for jsonl_file in tqdm(jsonl_files, desc=f"å¤„ç† {dataset_name}", dynamic_ncols=True):
            seq_name = Path(jsonl_file).stem.replace("_descriptions", "").replace("_done", "")
            save_path = os.path.join(out_dir, f"{seq_name}_pred.jsonl")

            # æ–­ç‚¹ç»­è·‘: æ£€æŸ¥å·²å¤„ç†çš„è¡Œæ•°
            processed = _count_lines(save_path)
            samples = load_and_fix_paths(jsonl_file, dataset_name, image_roots)

            if processed >= len(samples):
                continue

            pending = samples[processed:]

            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
            if not os.path.exists(save_path):
                with open(save_path, "w", encoding="utf-8"):
                    pass

            # å¤„ç†æ¯ä¸€å¸§
            for s in tqdm(pending, desc=f"åºåˆ— {seq_name}", leave=False, dynamic_ncols=True):
                img_path = s["image_path"]
                
                prompt = build_prompt(s["text_prompt"])

                # è°ƒç”¨æ¨ç†å¼•æ“
                if args.mode == "local":
                    raw_out = engine.chat(img_path, prompt, max_new_tokens=args.max_new_tokens)
                else:
                    raw_out = qwen3vl_api_chat(
                        image_path=img_path,
                        prompt=prompt,
                        model_name=args.api_model_name,
                        base_url=args.api_base_url,
                        api_key=args.api_key_env,
                        temperature=args.api_temperature,
                        max_tokens=args.api_max_tokens,
                        retries=args.api_retries,
                        retry_sleep=1.0,
                    )

                # å¤„ç†ç©ºè¾“å‡º
                if not raw_out:
                    record = s["original_item"].copy()
                    record["model_raw_response"] = raw_out
                    record["parsed_bboxes"] = []
                    record["parse_status"] = "empty_output"
                    with open(save_path, "a", encoding="utf-8") as f_out:
                        f_out.write(json.dumps(record, ensure_ascii=False) + "\n")
                    continue

                # è§£æ bbox
                with Image.open(img_path) as img:
                    w, h = img.size
                    parsed = extract_bboxes_from_model_output(raw_out, w, h)

                # ä¿å­˜ç»“æœ
                record = s["original_item"].copy()
                record["model_raw_response"] = raw_out
                record["parsed_bboxes"] = parsed
                record["parse_status"] = "ok" if parsed else "no_bbox_found"

                with open(save_path, "a", encoding="utf-8") as f_out:
                    f_out.write(json.dumps(record, ensure_ascii=False) + "\n")

                # å¯é€‰: ä¿å­˜å¯è§†åŒ–
                if vis_dir and parsed:
                    vis_path = os.path.join(vis_dir, f"{seq_name}_{s['frame_idx']}.jpg")
                    with Image.open(img_path) as img:
                        plot_bounding_boxes(img, parsed, vis_path)

    print("\nâœ… å…¨éƒ¨ä»»åŠ¡å®Œæˆ")


if __name__ == "__main__":
    main()
