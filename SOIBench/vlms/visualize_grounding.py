# -*- coding: utf-8 -*-
"""
SOIBench/vlms/visualize_grounding.py
å¯è§†åŒ– Grounding ç»“æœ
åŠŸèƒ½ï¼š
1ï¼‰è¯»å–å¤šä¸ªæ¨¡å‹çš„ Pred JSONL å’Œ GT JSONL
2ï¼‰åœ¨åŸå›¾ä¸Šç”» GT (ç»¿è‰²)ã€å¤šä¸ªæ¨¡å‹é¢„æµ‹ (ä¸åŒé¢œè‰²)ã€äººç±»åŸºçº¿ (è“è‰²)
3ï¼‰ä¿å­˜ä¸ºå›¾ç‰‡æˆ–è§†é¢‘
"""

import argparse
import json
import os
import cv2
import numpy as np
from tqdm import tqdm
from PIL import Image, ImageDraw, ImageFont


# ä¸ºä¸åŒæ¨¡å‹åˆ†é…é¢œè‰²
MODEL_COLORS = [
    "red", "orange", "purple", "magenta", "cyan", 
    "yellow", "pink", "brown", "gray", "olive"
]


def load_seq_data(jsonl_path, is_gt=False, load_human_baseline=False):
    """
    åŠ è½½å•ä¸ªåºåˆ—æ–‡ä»¶ï¼Œè¿”å› {frame_idx: (box, image_path)} å­—å…¸
    å‚æ•°:
        jsonl_path: JSONL æ–‡ä»¶è·¯å¾„
        is_gt: æ˜¯å¦ä¸º GT æ–‡ä»¶
        load_human_baseline: æ˜¯å¦åŠ è½½äººç±»åŸºçº¿
    è¿”å›:
        {frame_idx: (box, image_path)} å­—å…¸
    """
    data_map = {}
    if not os.path.exists(jsonl_path):
        return data_map

    last_valid_box = None  # ç”¨äº skip å¸§çš„å¡«å……
    
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            try:
                item = json.loads(line)
                
                fid = int(item.get("frame_idx", -1))
                if fid == -1:
                    continue
                
                is_skip = item.get("status") == "skip"
                img_path = item.get("image_path", "")

                if load_human_baseline:
                    # åŠ è½½äººç±»åŸºçº¿: ä» pred_boxes æå–
                    pred_boxes = item.get("pred_boxes", [])
                    
                    if is_skip:
                        # skip å¸§: ä½¿ç”¨ä¸Šä¸€ä¸ªæœ‰æ•ˆå¸§çš„ç»“æœ
                        if last_valid_box is not None:
                            data_map[fid] = (last_valid_box, img_path)
                    else:
                        # é skip å¸§: æå– pred_boxes
                        if pred_boxes and len(pred_boxes) > 0:
                            # pred_boxes æ ¼å¼: [[x1,y1], [x2,y2]] -> [x1,y1,x2,y2]
                            box = pred_boxes
                            if len(box) == 2 and len(box[0]) == 2:
                                box = [box[0][0], box[0][1], box[1][0], box[1][1]]
                            last_valid_box = box
                            data_map[fid] = (box, img_path)
                
                elif is_gt:
                    # GT æå–é€»è¾‘
                    if not is_skip:
                        box = item.get("gt_box") or item.get("bbox")
                        # gt_box æ ¼å¼: [[x1,y1], [x2,y2]] -> [x1,y1,x2,y2]
                        if box and len(box) == 2 and len(box[0]) == 2:
                            box = [box[0][0], box[0][1], box[1][0], box[1][1]]
                        if box:
                            data_map[fid] = (box, img_path)
                else:
                    # Pred æå–é€»è¾‘: å–ç¬¬ä¸€ä¸ªé¢„æµ‹æ¡†
                    p_boxes = item.get("parsed_bboxes") or item.get("parsed_bbox")
                    box = p_boxes[0] if (p_boxes and len(p_boxes) > 0) else None
                    if box:
                        data_map[fid] = (box, img_path)
                        
            except:
                continue
    return data_map


def draw_box(img, box, color, label=None):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶ bbox
    å‚æ•°:
        img: PIL Image å¯¹è±¡
        box: [x1, y1, x2, y2]
        color: é¢œè‰²
        label: æ ‡ç­¾æ–‡æœ¬
    è¿”å›:
        ç»˜åˆ¶åçš„ PIL Image
    """
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype("NotoSansCJK-Regular.ttc", size=20)
    except:
        font = ImageFont.load_default()
        
    x1, y1, x2, y2 = [int(v) for v in box]
    draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
    if label:
        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        text_bbox = draw.textbbox((x1, y1-25), label, font=font)
        draw.rectangle(text_bbox, fill=color)
        draw.text((x1, y1-25), label, fill="white", font=font)
    return img


def fix_image_path(rel_path, image_root):
    """
    ä¿®å¤å›¾åƒè·¯å¾„
    å‚æ•°:
        rel_path: ç›¸å¯¹è·¯å¾„
        image_root: å›¾åƒæ ¹ç›®å½•
    è¿”å›:
        ç»å¯¹è·¯å¾„
    """
    if not rel_path:
        return None
        
    if rel_path.startswith("/"):
        rel_path = rel_path[1:]
    
    # å°è¯•å¤šç§è·¯å¾„ç»„åˆ
    possible_paths = [
        rel_path if os.path.isabs(rel_path) else None,  # å·²ç»æ˜¯ç»å¯¹è·¯å¾„
        os.path.join(image_root, rel_path),
    ]
    
    # LaSOT ç‰¹æ®Šè·¯å¾„
    if len(rel_path) > 10:
        possible_paths.append(os.path.join(image_root, rel_path[6:10], rel_path))
    
    # MGIT/TNL2K ç‰¹æ®Šè·¯å¾„
    if len(rel_path.split('/')) > 2:
        parts = rel_path.split('/')
        possible_paths.append(os.path.join(image_root, parts[1], 'imgs', parts[2][1:]))
        possible_paths.append(os.path.join(image_root, parts[1], 'imgs', parts[2]))
    
    for p in possible_paths:
        if p and os.path.exists(p):
            return p
    
    return None


def main():
    parser = argparse.ArgumentParser(description="SOIBench Grounding å¯è§†åŒ–è„šæœ¬")
    
    parser.add_argument("--dataset", type=str, required=True, 
                        choices=["lasot", "mgit", "tnl2k"],
                        help="æ•°æ®é›†åç§°")
    parser.add_argument("--seq_name", type=str, required=True,
                        help="åºåˆ—åç§°")
    parser.add_argument("--pred_root", type=str, required=True,
                        help="é¢„æµ‹ç»“æœæ ¹ç›®å½•")
    parser.add_argument("--models", nargs='+', required=True,
                        help="è¦å¯è§†åŒ–çš„æ¨¡å‹ tag åˆ—è¡¨ï¼Œä¾‹å¦‚: model1 model2")
    parser.add_argument("--gt_file", type=str, required=True,
                        help="GT JSONL æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--image_root", type=str, required=True,
                        help="å›¾ç‰‡æ ¹ç›®å½•")
    parser.add_argument("--output_dir", type=str, default="./vis_results",
                        help="å¯è§†åŒ–ä¿å­˜ç›®å½•")
    parser.add_argument("--save_video", action="store_true",
                        help="æ˜¯å¦ä¿å­˜ä¸ºè§†é¢‘")
    parser.add_argument("--fps", type=int, default=30,
                        help="è§†é¢‘å¸§ç‡")
    parser.add_argument("--show_human_baseline", action="store_true",
                        help="æ˜¯å¦æ˜¾ç¤ºäººç±»åŸºçº¿ (ä» GT JSONL çš„ pred_boxes æå–)")
    
    args = parser.parse_args()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    print(f"\nğŸ“‚ å¯è§†åŒ–åºåˆ—: {args.seq_name}")
    print(f"ğŸ“Š æ¨¡å‹æ•°é‡: {len(args.models)}")
    
    # åŠ è½½ GT æ•°æ®
    gt_map = load_seq_data(args.gt_file, is_gt=True)
    
    # åŠ è½½äººç±»åŸºçº¿ (å¦‚æœéœ€è¦)
    human_map = {}
    if args.show_human_baseline:
        human_map = load_seq_data(args.gt_file, is_gt=False, load_human_baseline=True)
        print(f"ğŸ“Š äººç±»åŸºçº¿: {len(human_map)} å¸§")
    
    # åŠ è½½æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ
    model_maps = {}
    for model_tag in args.models:
        # å°è¯•å¤šç§é¢„æµ‹æ–‡ä»¶è·¯å¾„ç»“æ„
        possible_paths = [
            os.path.join(args.pred_root, args.dataset, model_tag, f"{args.seq_name}_pred.jsonl"),
            os.path.join(args.pred_root, args.dataset, f"{args.seq_name}_{model_tag}_pred.jsonl")
        ]
        
        pred_file = None
        for p in possible_paths:
            if os.path.exists(p):
                pred_file = p
                break
        
        if pred_file:
            model_maps[model_tag] = load_seq_data(pred_file, is_gt=False)
            print(f"âœ… åŠ è½½æ¨¡å‹ {model_tag}: {len(model_maps[model_tag])} å¸§")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°æ¨¡å‹ {model_tag} çš„é¢„æµ‹æ–‡ä»¶")
            model_maps[model_tag] = {}
    
    # è·å–æ‰€æœ‰å¸§ç´¢å¼•
    all_fids = set(gt_map.keys()) | set(human_map.keys())
    for model_map in model_maps.values():
        all_fids |= set(model_map.keys())
    all_fids = sorted(list(all_fids))
    
    if not all_fids:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¸§æ•°æ®")
        return

    print(f"ğŸ“Š å…± {len(all_fids)} å¸§")
    
    # å‡†å¤‡è§†é¢‘å†™å…¥å™¨
    video_writer = None
    if args.save_video:
        video_path = os.path.join(args.output_dir, f"{args.seq_name}_compare.mp4")

    # å¤„ç†æ¯ä¸€å¸§
    for fid in tqdm(all_fids, desc="å¯è§†åŒ–"):
        # è·å–å›¾åƒè·¯å¾„
        img_path = None
        if fid in gt_map:
            _, img_path = gt_map[fid]
        elif fid in human_map:
            _, img_path = human_map[fid]
        else:
            for model_map in model_maps.values():
                if fid in model_map:
                    _, img_path = model_map[fid]
                    break
        
        # ä¿®å¤å›¾åƒè·¯å¾„
        if img_path:
            img_path = fix_image_path(img_path, args.image_root)
        
        if not img_path or not os.path.exists(img_path):
            continue
            
        # è¯»å–å›¾åƒ
        img = Image.open(img_path).convert("RGB")
        
        # ç”» GT (ç»¿è‰²)
        if fid in gt_map:
            gt_box, _ = gt_map[fid]
            img = draw_box(img, gt_box, "green", "GT")
        
        # ç”»äººç±»åŸºçº¿ (è“è‰²)
        if args.show_human_baseline and fid in human_map:
            human_box, _ = human_map[fid]
            img = draw_box(img, human_box, "blue", "Human")
        
        # ç”»æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ (ä¸åŒé¢œè‰²)
        for idx, (model_tag, model_map) in enumerate(model_maps.items()):
            if fid in model_map:
                pred_box, _ = model_map[fid]
                color = MODEL_COLORS[idx % len(MODEL_COLORS)]
                img = draw_box(img, pred_box, color, model_tag)
            
        # ä¿å­˜å›¾ç‰‡
        if not args.save_video:
            save_path = os.path.join(args.output_dir, args.seq_name, f"{fid:08d}.jpg")
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            img.save(save_path)
        else:
            # è½¬æ¢ä¸º OpenCV æ ¼å¼å†™å…¥è§†é¢‘
            frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            if video_writer is None:
                h, w = frame.shape[:2]
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                video_writer = cv2.VideoWriter(video_path, fourcc, args.fps, (w, h))
            video_writer.write(frame)

    # é‡Šæ”¾è§†é¢‘å†™å…¥å™¨
    if video_writer:
        video_writer.release()
        print(f"âœ… è§†é¢‘å·²ä¿å­˜: {video_path}")
    else:
        print(f"âœ… å›¾ç‰‡å·²ä¿å­˜è‡³: {os.path.join(args.output_dir, args.seq_name)}")


if __name__ == "__main__":
    main()
