# -*- coding: utf-8 -*-
"""
SOIBench/vlms/eval_results.py
è¯„æµ‹ Grounding ç»“æœ
åŠŸèƒ½ï¼š
1ï¼‰åŠ è½½ GT å’Œ Pred JSONL
2ï¼‰è®¡ç®— IoU æŒ‡æ ‡
3ï¼‰ç»˜åˆ¶ Success Plot
4ï¼‰ç”Ÿæˆè¯„æµ‹æŠ¥å‘Šï¼ˆæ•´ä½“ + å„å­æ•°æ®é›†ï¼‰
"""

import argparse
import glob
import json
import os
import numpy as np
import matplotlib.pyplot as plt
from prettytable import PrettyTable
from tqdm import tqdm


# é»˜è®¤æ¨¡å‹åæ˜ å°„è¡¨ï¼ˆå­˜å‚¨å -> æ˜¾ç¤ºåï¼‰
DEFAULT_MODEL_NAME_MAP = {
    # Qwen3VL ç³»åˆ—
    "local_qwen3-vl-4b-instruct": "Qwen3-VL-4B",
    "local_qwen3-vl-8b-instruct": "Qwen3-VL-8B",
    "api_qwen3-vl-235b-a22b-instruct": "Qwen3-VL-235B",
    "qwen3vl_4b": "Qwen3-VL-4B",
    "qwen3vl_api": "Qwen3-VL-API",
    
    # å…¶ä»–å¸¸è§æ¨¡å‹
    "gpt4v": "GPT-4V",
    "gemini": "Gemini-Pro",
    "claude": "Claude-3",
    
    # äººç±»åŸºçº¿
    "Human_Baseline": "Human",
}


def get_display_name(model_tag, name_map=None):
    """
    è·å–æ¨¡å‹çš„æ˜¾ç¤ºåç§°
    å‚æ•°:
        model_tag: æ¨¡å‹å­˜å‚¨æ ‡ç­¾
        name_map: è‡ªå®šä¹‰åç§°æ˜ å°„å­—å…¸
    è¿”å›:
        æ˜¾ç¤ºåç§°
    """
    if name_map and model_tag in name_map:
        return name_map[model_tag]
    if model_tag in DEFAULT_MODEL_NAME_MAP:
        return DEFAULT_MODEL_NAME_MAP[model_tag]
    return model_tag  # å¦‚æœæ²¡æœ‰æ˜ å°„ï¼Œè¿”å›åŸå§‹åç§°


def calculate_iou(box1, box2):
    """
    è®¡ç®—ä¸¤ä¸ª bbox çš„ IoU
    å‚æ•°:
        box1, box2: [x1, y1, x2, y2] æ ¼å¼çš„ bbox
    è¿”å›:
        IoU å€¼ (0-1)
    """
    if not box1 or not box2:
        return 0.0
    
    # å…¼å®¹å¯èƒ½å‡ºç°çš„åµŒå¥— list
    b1 = [float(x) for x in (box1[0] if isinstance(box1[0], list) else box1)]
    b2 = [float(x) for x in (box2[0] if isinstance(box2[0], list) else box2)]
    
    # è®¡ç®—äº¤é›†
    x1 = max(b1[0], b2[0])
    y1 = max(b1[1], b2[1])
    x2 = min(b1[2], b2[2])
    y2 = min(b1[3], b2[3])
    
    inter_w = max(0, x2 - x1)
    inter_h = max(0, y2 - y1)
    inter_area = inter_w * inter_h
    
    # è®¡ç®—å¹¶é›†
    area1 = max(0, b1[2] - b1[0]) * max(0, b1[3] - b1[1])
    area2 = max(0, b2[2] - b2[0]) * max(0, b2[3] - b2[1])
    union = area1 + area2 - inter_area
    
    return inter_area / union if union > 0 else 0.0


def load_seq_data(jsonl_path, is_gt=False, load_human_baseline=False, skip_consecutive_frames=False):
    """
    åŠ è½½å•ä¸ªåºåˆ—æ–‡ä»¶ï¼Œè¿”å› {frame_idx: box} å­—å…¸
    å‚æ•°:
        jsonl_path: JSONL æ–‡ä»¶è·¯å¾„
        is_gt: æ˜¯å¦ä¸º GT æ–‡ä»¶
        load_human_baseline: æ˜¯å¦åŠ è½½äººç±»åŸºçº¿ (ä» GT æ–‡ä»¶çš„ pred_boxes å­—æ®µ)
        skip_consecutive_frames: æ˜¯å¦è·³è¿‡è¿ç»­å¸§ (True=ä¸¥æ ¼æ¨¡å¼, False=å®Œæ•´æ¨¡å¼)
    è¿”å›:
        {frame_idx: box} å­—å…¸
    """
    data_map = {}
    if not os.path.exists(jsonl_path):
        return data_map

    last_valid_box = None  # ç”¨äº skip å¸§çš„å¡«å……
    
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            try:
                item = json.loads(line)
                
                fid = int(item.get("frame_idx", -1))
                if fid == -1:
                    continue
                
                is_skip = item.get("status") == "skip"

                if load_human_baseline:
                    # åŠ è½½äººç±»åŸºçº¿: ä» pred_boxes æå–
                    pred_boxes = item.get("pred_boxes", [])
                    
                    if is_skip:
                        # skip å¸§: ä½¿ç”¨ä¸Šä¸€ä¸ªæœ‰æ•ˆå¸§çš„ç»“æœ
                        if last_valid_box is not None:
                            data_map[fid] = last_valid_box
                    else:
                        # é skip å¸§: æå– pred_boxes
                        if pred_boxes and len(pred_boxes) > 0:
                            # pred_boxes æ ¼å¼: [[x1,y1], [x2,y2]] -> [x1,y1,x2,y2]
                            box = pred_boxes
                            if len(box) == 2 and len(box[0]) == 2:
                                box = [box[0][0], box[0][1], box[1][0], box[1][1]]
                            last_valid_box = box
                            data_map[fid] = box
                        
                elif is_gt:
                    # GT æå–é€»è¾‘
                    # æ³¨æ„: å¦‚æœ skip_consecutive_frames=Trueï¼Œåˆ™è·³è¿‡ skip å¸§
                    # å¦‚æœ skip_consecutive_frames=Falseï¼Œåˆ™åŠ è½½æ‰€æœ‰å¸§ï¼ˆç®—æ³•è¯„æµ‹æ‰€æœ‰å¸§ï¼‰
                    if skip_consecutive_frames and is_skip:
                        continue  # ä¸¥æ ¼æ¨¡å¼: è·³è¿‡ skip å¸§
                    
                    box = item.get("gt_box") or item.get("bbox")
                    # gt_box æ ¼å¼: [[x1,y1], [x2,y2]] -> [x1,y1,x2,y2]
                    if box and len(box) == 2 and len(box[0]) == 2:
                        box = [box[0][0], box[0][1], box[1][0], box[1][1]]
                    if box:
                        data_map[fid] = box
                else:
                    # Pred æå–é€»è¾‘: å–ç¬¬ä¸€ä¸ªé¢„æµ‹æ¡†
                    p_boxes = item.get("parsed_bboxes") or item.get("parsed_bbox")
                    box = p_boxes[0] if (p_boxes and len(p_boxes) > 0) else None
                    if box:
                        data_map[fid] = box
                        
            except:
                continue
    return data_map


def evaluate_dataset(ds_name, gt_root, pred_root, model_tags, add_human_baseline=False, skip_consecutive_frames=False):
    """
    è¯„æµ‹å•ä¸ªæ•°æ®é›†
    å‚æ•°:
        ds_name: æ•°æ®é›†åç§°
        gt_root: GT JSONL æ–‡ä»¶æ ¹ç›®å½•
        pred_root: é¢„æµ‹ç»“æœæ ¹ç›®å½•
        model_tags: æ¨¡å‹æ ‡ç­¾åˆ—è¡¨
        add_human_baseline: æ˜¯å¦æ·»åŠ äººç±»åŸºçº¿
        skip_consecutive_frames: æ˜¯å¦è·³è¿‡è¿ç»­å¸§
            - True: ä¸¥æ ¼æ¨¡å¼ï¼Œç®—æ³•å’Œäººç±»éƒ½åªè¯„æµ‹é skip å¸§
            - False: å®Œæ•´æ¨¡å¼ï¼Œç®—æ³•è¯„æµ‹æ‰€æœ‰å¸§ï¼Œäººç±»åœ¨ skip å¸§å¤ç”¨ä¸Šä¸€å¸§
    è¿”å›:
        {model_name: [all_ious_list]} å­—å…¸
    """
    # æŸ¥æ‰¾è¯¥æ•°æ®é›†æ‰€æœ‰ GT æ–‡ä»¶
    gt_files = sorted(glob.glob(os.path.join(gt_root, "*.jsonl")))
    if not gt_files:
        print(f"âš ï¸  {ds_name} æœªæ‰¾åˆ° GT æ–‡ä»¶ï¼Œè·³è¿‡ã€‚")
        return {}

    # å­˜å‚¨æ¯ä¸ªæ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸‹çš„æ‰€æœ‰å¸§ IoU
    all_tags = model_tags + (["Human_Baseline"] if add_human_baseline else [])
    model_ious = {tag: [] for tag in all_tags}
    
    print(f"ğŸ”„ æ­£åœ¨è¯„æµ‹ {ds_name} ({len(gt_files)} ä¸ªåºåˆ—)...")

    for gt_path in tqdm(gt_files, leave=False, desc=f"è¯„æµ‹ {ds_name}"):
        seq_name = os.path.basename(gt_path).replace("_descriptions.jsonl", "").replace(".jsonl", "")
        
        # åŠ è½½ GT {frame: box}
        gt_map = load_seq_data(gt_path, is_gt=True, skip_consecutive_frames=skip_consecutive_frames)
        if not gt_map:
            continue
        
        # åŠ è½½äººç±»åŸºçº¿ (å¦‚æœéœ€è¦)
        human_map = {}
        if add_human_baseline:
            human_map = load_seq_data(gt_path, is_gt=False, load_human_baseline=True)

        # éå†æ¯ä¸ªæ¨¡å‹
        for tag in model_tags:
            # å°è¯•å¤šç§é¢„æµ‹æ–‡ä»¶è·¯å¾„ç»“æ„
            # 1. pred_root/dataset_name/tag/seq_name_pred.jsonl (æ–°ç»“æ„)
            # 2. pred_root/dataset_name/seq_name_tag_pred.jsonl (æ—§ç»“æ„)
            
            possible_paths = [
                os.path.join(pred_root, ds_name, tag, f"{seq_name}_pred.jsonl"),
                os.path.join(pred_root, ds_name, f"{seq_name}_{tag}_pred.jsonl")
            ]
            
            pred_path = None
            for p in possible_paths:
                if os.path.exists(p):
                    pred_path = p
                    break
            
            # åŠ è½½ Pred {frame: box}
            pred_map = load_seq_data(pred_path, is_gt=False) if pred_path else {}
            
            # é€å¸§å¯¹é½è®¡ç®— (ä»¥ GT ä¸ºå‡†)
            for fid, gt_box in gt_map.items():
                pred_box = pred_map.get(fid)
                iou = calculate_iou(pred_box, gt_box)
                model_ious[tag].append(iou)
        
        # è®¡ç®—äººç±»åŸºçº¿ IoU
        if add_human_baseline:
            for fid, gt_box in gt_map.items():
                human_box = human_map.get(fid)
                iou = calculate_iou(human_box, gt_box)
                model_ious["Human_Baseline"].append(iou)
                
    return model_ious


def plot_success_curves(results, output_dir, ds_name, name_map=None):
    """
    ç»˜åˆ¶ Success Plot (æˆåŠŸç‡æ›²çº¿)
    å‚æ•°:
        results: {model_name: [iou_list]} å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        ds_name: æ•°æ®é›†åç§°
        name_map: æ¨¡å‹åç§°æ˜ å°„å­—å…¸
    """
    plt.figure(figsize=(10, 7))
    plt.title(f"Success Plot - {ds_name.upper()}", fontsize=16)
    plt.xlabel("Overlap Threshold (IoU)", fontsize=14)
    plt.ylabel("Success Rate", fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    
    thresholds = np.linspace(0, 1, 21)  # 0, 0.05, ..., 1.0
    
    # æŒ‰ AUC æ’åºå›¾ä¾‹
    model_stats = []
    
    for model_name, ious in results.items():
        if not ious:
            continue
        ious_arr = np.array(ious)
        
        # è®¡ç®—æ›²çº¿ç‚¹: æ¯ä¸ªé˜ˆå€¼ä¸‹çš„æˆåŠŸç‡
        curve = [np.mean(ious_arr >= thr) for thr in thresholds]
        auc = np.mean(curve)  # è¿‘ä¼¼ AUC
        model_stats.append((model_name, auc, curve))
        
    # æŒ‰ AUC é™åºæ’åº
    model_stats.sort(key=lambda x: x[1], reverse=True)
    
    # ç»˜åˆ¶æ›²çº¿
    for model_name, auc, curve in model_stats:
        display_name = get_display_name(model_name, name_map)
        plt.plot(thresholds, curve, linewidth=2, label=f"{display_name} [{auc:.3f}]")
        
    plt.legend(loc='lower left', fontsize=12)
    
    save_path = os.path.join(output_dir, f"{ds_name}_success_plot.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“ˆ æ›²çº¿å›¾å·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description="SOIBench Grounding è¯„æµ‹è„šæœ¬")
    
    parser.add_argument("--pred_root", type=str, default="./results",
                        help="é¢„æµ‹ç»“æœæ ¹ç›®å½•")
    parser.add_argument("--output_dir", type=str, default="./eval_results",
                        help="è¯„æµ‹ç»“æœä¿å­˜ç›®å½•")
    parser.add_argument("--models", nargs='+', required=True,
                        help="è¦å¯¹æ¯”çš„æ¨¡å‹ tag åˆ—è¡¨ï¼Œä¾‹å¦‚: local_run api_run")
    parser.add_argument("--datasets", nargs='+', default=["lasot", "mgit", "tnl2k"],
                        help="è¦è¯„æµ‹çš„æ•°æ®é›†")
    
    # GT æ ¹ç›®å½•
    parser.add_argument("--lasot_gt_root", type=str, 
                        default="/home/member/data2/wyp/SUTrack/SOIBench/data/test/lasot",
                        help="LaSOT GT JSONL æ ¹ç›®å½•")
    parser.add_argument("--mgit_gt_root", type=str, 
                        default="/home/member/data2/wyp/SUTrack/SOIBench/data/test/mgit",
                        help="MGIT GT JSONL æ ¹ç›®å½•")
    parser.add_argument("--tnl2k_gt_root", type=str, 
                        default="/home/member/data2/wyp/SUTrack/SOIBench/data/test/tnl2k",
                        help="TNL2K GT JSONL æ ¹ç›®å½•")
    
    # äººç±»åŸºçº¿
    parser.add_argument("--add_human_baseline", action="store_true",
                        help="æ˜¯å¦æ·»åŠ äººç±»åŸºçº¿å¯¹æ¯” (ä» GT JSONL çš„ pred_boxes å­—æ®µæå–)")
    parser.add_argument("--skip_consecutive_frames", action="store_true",
                        help="æ˜¯å¦è·³è¿‡è¿ç»­å¸§è¯„æµ‹ (ä¸¥æ ¼æ¨¡å¼: ç®—æ³•å’Œäººç±»éƒ½åªè¯„æµ‹ SOI å¸§; é»˜è®¤: ç®—æ³•è¯„æµ‹æ‰€æœ‰å¸§ï¼Œäººç±»å¤ç”¨)")
    parser.add_argument("--model_names", type=str, default=None,
                        help="æ¨¡å‹åç§°æ˜ å°„ï¼Œæ ¼å¼: 'tag1:Name1,tag2:Name2'ï¼Œä¾‹å¦‚: 'local_qwen3-vl-4b:Qwen-4B,api_model:API-Model'")

    args = parser.parse_args()
    
    # è§£æè‡ªå®šä¹‰æ¨¡å‹åæ˜ å°„
    custom_name_map = {}
    if args.model_names:
        for pair in args.model_names.split(','):
            if ':' in pair:
                tag, name = pair.split(':', 1)
                custom_name_map[tag.strip()] = name.strip()
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # æ„å»º GT æ ¹ç›®å½•å­—å…¸
    gt_roots = {
        "lasot": args.lasot_gt_root,
        "mgit": args.mgit_gt_root,
        "tnl2k": args.tnl2k_gt_root
    }
    
    print("\n" + "="*60)
    print("SOIBench Grounding è¯„æµ‹")
    print("="*60)
    
    # æ”¶é›†æ‰€æœ‰æ•°æ®é›†çš„ç»“æœ
    all_models = args.models + (["Human_Baseline"] if args.add_human_baseline else [])
    all_dataset_results = {model: [] for model in all_models}  # {model: [æ‰€æœ‰æ•°æ®é›†çš„ IoU åˆå¹¶]}
    per_dataset_results = {}  # {dataset: {model: [IoU]}}
    
    for ds_name in args.datasets:
        gt_root = gt_roots.get(ds_name)
        
        if not gt_root or not os.path.exists(gt_root):
            print(f"âŒ æ— æ³•æ‰¾åˆ° {ds_name} çš„ GT ç›®å½•: {gt_root}ï¼Œè·³è¿‡")
            continue
        
        # è®¡ç®—è¯¥æ•°æ®é›†ä¸‹æ‰€æœ‰æ¨¡å‹çš„ IoU
        dataset_results = evaluate_dataset(ds_name, gt_root, args.pred_root, args.models, args.add_human_baseline, args.skip_consecutive_frames)
        
        if not dataset_results:
            continue
        
        # ä¿å­˜è¯¥æ•°æ®é›†çš„ç»“æœ
        per_dataset_results[ds_name] = dataset_results
        
        # åˆå¹¶åˆ°æ€»ç»“æœä¸­
        for model in all_models:
            all_dataset_results[model].extend(dataset_results[model])
        
        # ç»˜åˆ¶è¯¥æ•°æ®é›†çš„ Success Plot
        plot_success_curves(dataset_results, args.output_dir, ds_name, custom_name_map)
    
    # ç»˜åˆ¶æ•´ä½“ SOIBench Success Plot
    if any(all_dataset_results.values()):
        plot_success_curves(all_dataset_results, args.output_dir, "SOIBench_Overall", custom_name_map)
    
    # ç”ŸæˆæŠ¥å‘Šè¡¨æ ¼
    print("\n" + "="*60)
    print("è¯„æµ‹ç»“æœæ±‡æ€»")
    print("="*60)
    
    # 1. æ•´ä½“ SOIBench æŒ‡æ ‡
    if any(all_dataset_results.values()):
        print("\nã€æ•´ä½“ SOIBench æŒ‡æ ‡ã€‘")
        overall_table = PrettyTable()
        overall_table.field_names = ["Model", "AUC", "OP@0.50", "OP@0.75", "Total Frames"]
        
        for model in all_models:
            ious = np.array(all_dataset_results[model])
            if len(ious) == 0:
                overall_table.add_row([model, 0.0, 0.0, 0.0, 0])
                continue
                
            # AUC: 0-1 é˜ˆå€¼ä¸‹çš„å¹³å‡æˆåŠŸç‡
            thresholds = np.linspace(0, 1, 21)
            curve = [np.mean(ious >= thr) for thr in thresholds]
            auc = np.mean(curve)
            
            # OP@0.5: IoU >= 0.5 çš„æ¯”ä¾‹
            op50 = np.mean(ious >= 0.50)
            
            # OP@0.75: IoU >= 0.75 çš„æ¯”ä¾‹
            op75 = np.mean(ious >= 0.75)
            
            overall_table.add_row([get_display_name(model, custom_name_map), f"{auc:.3f}", f"{op50:.3f}", f"{op75:.3f}", len(ious)])
        
        print(overall_table)
    
    # 2. å„å­æ•°æ®é›†æŒ‡æ ‡
    if per_dataset_results:
        print("\nã€å„å­æ•°æ®é›†æŒ‡æ ‡ã€‘")
        detail_table = PrettyTable()
        detail_table.field_names = ["Dataset", "Model", "AUC", "OP@0.50", "OP@0.75", "Frames"]
        
        for ds_name in args.datasets:
            if ds_name not in per_dataset_results:
                continue
                
            dataset_results = per_dataset_results[ds_name]
            
            for model in all_models:
                ious = np.array(dataset_results[model])
                if len(ious) == 0:
                    detail_table.add_row([ds_name, model, 0.0, 0.0, 0.0, 0])
                    continue
                    
                # AUC: 0-1 é˜ˆå€¼ä¸‹çš„å¹³å‡æˆåŠŸç‡
                thresholds = np.linspace(0, 1, 21)
                curve = [np.mean(ious >= thr) for thr in thresholds]
                auc = np.mean(curve)
                
                # OP@0.5: IoU >= 0.5 çš„æ¯”ä¾‹
                op50 = np.mean(ious >= 0.50)
                
                # OP@0.75: IoU >= 0.75 çš„æ¯”ä¾‹
                op75 = np.mean(ious >= 0.75)
                
                detail_table.add_row([ds_name, get_display_name(model, custom_name_map), f"{auc:.3f}", f"{op50:.3f}", f"{op75:.3f}", len(ious)])
            
            detail_table.add_row(["---", "---", "---", "---", "---", "---"])
        
        print(detail_table)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(args.output_dir, "report.txt")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("="*60 + "\n")
        f.write("SOIBench Grounding è¯„æµ‹æŠ¥å‘Š\n")
        f.write("="*60 + "\n\n")
        
        if any(all_dataset_results.values()):
            f.write("ã€æ•´ä½“ SOIBench æŒ‡æ ‡ã€‘\n")
            f.write(str(overall_table) + "\n\n")
        
        if per_dataset_results:
            f.write("ã€å„å­æ•°æ®é›†æŒ‡æ ‡ã€‘\n")
            f.write(str(detail_table) + "\n")
    
    print(f"\nğŸ“Š æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


if __name__ == "__main__":
    main()
