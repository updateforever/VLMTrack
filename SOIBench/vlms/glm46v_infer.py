# -*- coding: utf-8 -*-
"""
SOIBench/vlms/glm46v_infer.py
GLM-4.6V æ¨ç†å¼•æ“
æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œ API ä¸¤ç§æ¨¡å¼
é»˜è®¤ä½¿ç”¨ç¡…åŸºæµåŠ¨ API
"""

import os
import re
import json
import torch
from PIL import Image


class GLM46VLocalEngine:
    """
    GLM-4.6V æœ¬åœ°æ¨ç†å¼•æ“
    ä½¿ç”¨ transformers åŠ è½½æ¨¡å‹
    """
    
    def __init__(
        self,
        model_path: str = "/home/member/data1/MODEL_WEIGHTS_PUBLIC/GLM-4.6V-Flash/",
        device_map: str = "auto",
    ):
        from transformers import AutoModelForCausalLM, AutoTokenizer
        
        print(f"ğŸš€ åŠ è½½ GLM-4.6V æœ¬åœ°æ¨¡å‹: {model_path}")
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype="auto",
            device_map=device_map,
            trust_remote_code=True
        ).eval()
        
        print("âœ… GLM-4.6V æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = 512) -> str:
        """
        å•å¼ å›¾æ¨ç†
        
        å‚æ•°:
            image_path: å›¾åƒè·¯å¾„
            prompt: æ–‡æœ¬æç¤ºï¼ˆç›®æ ‡æè¿°ï¼‰
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            
        è¿”å›:
            æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        """
        # æ„é€  grounding prompt
        full_prompt = f"Please pinpoint the bounding box in the image as per the given description: {prompt}"
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # æ„é€ è¾“å…¥
        inputs = self.tokenizer.apply_chat_template(
            [{"role": "user", "image": image, "content": full_prompt}],
            add_generation_prompt=True,
            tokenize=True,
            return_tensors="pt",
            return_dict=True
        )
        
        inputs = inputs.to(self.model.device)
        
        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,
                do_sample=False,  # ä½¿ç”¨è´ªå©ªè§£ç 
                temperature=0.1,
            )
        
        # è§£ç 
        response = self.tokenizer.decode(
            outputs[0][inputs['input_ids'].shape[1]:],
            skip_special_tokens=False
        )
        
        return response


class GLM46VAPIEngine:
    """
    GLM-4.6V API æ¨ç†å¼•æ“
    ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
    é»˜è®¤ä½¿ç”¨ç¡…åŸºæµåŠ¨ API
    """
    
    def __init__(
        self,
        api_key: str = None,
        api_base_url: str = "https://api.siliconflow.cn/v1",
        model_name: str = "zai-org/GLM-4.6V",
        temperature: float = 0.1,
        max_tokens: int = 512,
        retries: int = 3,
    ):
        from openai import OpenAI
        
        # è·å– API Key
        if api_key is None:
            # ä¼˜å…ˆä½¿ç”¨ SILICONFLOW_API_KEYï¼Œå…¶æ¬¡æ˜¯ ZHIPUAI_API_KEY
            api_key = os.getenv("SILICONFLOW_API_KEY") or os.getenv("ZHIPUAI_API_KEY")
            if not api_key:
                raise ValueError("è¯·è®¾ç½® SILICONFLOW_API_KEY æˆ– ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œæˆ–ä¼ å…¥ api_key å‚æ•°")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url=api_base_url
        )
        
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.retries = retries
        
        print(f"ğŸš€ åˆå§‹åŒ– GLM-4.6V API å¼•æ“")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   Base URL: {api_base_url}")
    
    def chat(self, image_path: str, prompt: str, max_new_tokens: int = None) -> str:
        """
        å•å¼ å›¾æ¨ç†
        
        å‚æ•°:
            image_path: å›¾åƒè·¯å¾„
            prompt: æ–‡æœ¬æç¤ºï¼ˆç›®æ ‡æè¿°ï¼‰
            max_new_tokens: æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é»˜è®¤å€¼ï¼‰
            
        è¿”å›:
            æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        """
        import base64
        import time
        
        # è¯»å–å¹¶ç¼–ç å›¾åƒ
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        # æ„é€  grounding prompt
        full_prompt = f"Please pinpoint the bounding box in the image as per the given description: {prompt}"
        
        # æ„é€ æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}"
                        }
                    },
                    {
                        "type": "text",
                        "text": full_prompt
                    }
                ]
            }
        ]
        
        # é‡è¯•é€»è¾‘
        for attempt in range(self.retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=max_new_tokens or self.max_tokens,
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                if attempt < self.retries - 1:
                    wait_time = 2 ** attempt
                    print(f"âš ï¸  API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.retries}): {e}")
                    print(f"   ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise


def parse_glm46v_bbox(response: str, image_width: int, image_height: int):
    """
    è§£æ GLM-4.6V çš„ bbox è¾“å‡º
    
    GLM-4.6V è¾“å‡ºæ ¼å¼:
    - ä½¿ç”¨ <|begin_of_box|> å’Œ <|end_of_box|> æ ‡è®°
    - åæ ‡æ ¼å¼: [x1, y1, x2, y2] æˆ– [[x1, y1, x2, y2]]
    - åæ ‡å€¼æ˜¯å½’ä¸€åŒ–åä¹˜ä»¥ 1000 çš„æ•´æ•°
    
    å‚æ•°:
        response: æ¨¡å‹è¾“å‡ºæ–‡æœ¬
        image_width: å›¾åƒå®½åº¦
        image_height: å›¾åƒé«˜åº¦
        
    è¿”å›:
        [[x1, y1, x2, y2], ...] åƒç´ åæ ‡åˆ—è¡¨
    """
    bboxes = []
    
    # æå– <|begin_of_box|> å’Œ <|end_of_box|> ä¹‹é—´çš„å†…å®¹
    box_pattern = r'<\|begin_of_box\|>(.*?)<\|end_of_box\|>'
    matches = re.findall(box_pattern, response, re.DOTALL)
    
    for match in matches:
        # æå–æ•°å­—åæ ‡
        # æ”¯æŒå¤šç§æ‹¬å·æ ¼å¼: [], [[]], (), <>, ç­‰
        coord_pattern = r'[\[\(<]?\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*[\]\)>]?'
        coords = re.findall(coord_pattern, match)
        
        for coord in coords:
            try:
                # å½’ä¸€åŒ–åæ ‡ (0-1000) -> åƒç´ åæ ‡
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                # è½¬æ¢ä¸ºåƒç´ åæ ‡
                x1 = (x1_norm / 1000.0) * image_width
                y1 = (y1_norm / 1000.0) * image_height
                x2 = (x2_norm / 1000.0) * image_width
                y2 = (y2_norm / 1000.0) * image_height
                
                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1 = max(0, min(x1, image_width))
                y1 = max(0, min(y1, image_height))
                x2 = max(0, min(x2, image_width))
                y2 = max(0, min(y2, image_height))
                
                bboxes.append([x1, y1, x2, y2])
                
            except (ValueError, IndexError) as e:
                print(f"âš ï¸  è§£æåæ ‡å¤±è´¥: {coord}, é”™è¯¯: {e}")
                continue
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹æ®Šæ ‡è®°ï¼Œå°è¯•ç›´æ¥æå–æ•°å­—
    if not bboxes:
        # å°è¯•æå–ä»»ä½•å½¢å¼çš„å››å…ƒç»„æ•°å­—
        fallback_pattern = r'\[?\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\]?'
        coords = re.findall(fallback_pattern, response)
        
        for coord in coords:
            try:
                x1_norm, y1_norm, x2_norm, y2_norm = map(int, coord)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å½’ä¸€åŒ–åæ ‡ (0-1000)
                if all(0 <= c <= 1000 for c in [x1_norm, y1_norm, x2_norm, y2_norm]):
                    x1 = (x1_norm / 1000.0) * image_width
                    y1 = (y1_norm / 1000.0) * image_height
                    x2 = (x2_norm / 1000.0) * image_width
                    y2 = (y2_norm / 1000.0) * image_height
                    
                    x1 = max(0, min(x1, image_width))
                    y1 = max(0, min(y1, image_height))
                    x2 = max(0, min(x2, image_width))
                    y2 = max(0, min(y2, image_height))
                    
                    bboxes.append([x1, y1, x2, y2])
                    
            except (ValueError, IndexError):
                continue
    
    return bboxes


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•æœ¬åœ°æ¨¡å‹
    # engine = GLM46VLocalEngine()
    
    # æµ‹è¯•ç¡…åŸºæµåŠ¨ API
    engine = GLM46VAPIEngine()
    
    # æµ‹è¯•æ¨ç†
    image_path = "test.jpg"
    prompt = "A red car"
    
    response = engine.chat(image_path, prompt)
    print(f"æ¨¡å‹è¾“å‡º: {response}")
    
    # è§£æ bbox
    img = Image.open(image_path)
    bboxes = parse_glm46v_bbox(response, img.width, img.height)
    print(f"è§£æçš„ bbox: {bboxes}")